filename: reading-yelp-menus-with-ocr.html
title: Reading Yelp Menus with OCR
slug: reading-yelp-menus-with-ocr
description: An attempt to read pictures of restaurant menus with ABBYY OCR SDK.
date: 3/17/2014


Back in 2012, [Yelp introduced menus][1] - a way to see pictures, reviews, and prices of individual items.
Prior to that I remember looking through reviews of a restaurant to see what other people suggested.
Since the menus weren't online until then, many people thought it would be a good idea to take pictures of
the menus for others to see. Most of these 'menu pictures' are taken with low-res camera phones in a dimly 
lit room. Others are decent, like the example I picked out:

![A menu picture from Yelp](/static/img/example_yelp_menu.jpg)

Lately I've been interested in computer vision and optical character recognition. For those of you not familiar
with OCR, it's an area of computer vision concerned with taking images containing text, and extracting computer-readable
text. It's used in check scanning systems in banks, and by post offices to read packages. <i>It's also one of the reasons
CAPTCHAs are becoming so difficult to read. I wanted to try out a few APIs to see what kind of results I could get with an
out-of-box OCR solution. My goal was to see how well it would perform on some of the menu pictures. I ended up going with
[ABBYY OCR API][2] and modifying some of their [example Python code][3]. Here's how it works from the command line:

terminal:
    $ python ABBYY/process.py example.jpg output.txt
    Uploading...
    Result was written to output.txt
    $ cat output.txt
    r.nm < hi m.imma carmela - tomato, mozzarella and fresh basil 13
    Strozzapreti with sausage, peas and wild mushrooms 12
    Spaghetti with clams, zucchini, garlic and parsley 15
    ...
endterminal

### A step further ###
The only thing that this really proves is that it's possible to read at least some data from bad menu pictures. While testing this
on a handful of pictures, I noticed that some restaurants didn't have their official menu listed, but had a picture of it. Having 
half of a menu posted by an unproven OCR algorithm would probably cause more harm than good, but the data might be useful for keywords
and category classification.

### Not good enough ###
Structure seems to be the key ingredient to achieve accuracy with OCR. Having random fancy fonts mixed with small, low-res images is not
good enough for most practical uses. I've been playing around with [Tesseract][4] and have had a similar experience. After training the engine
on a single font, it performs pretty well for clear images containing that font. Character and word recognition seem to have great potential, particularly if developers could use it for broad purposes. 


[1]: http://officialblog.yelp.com/2012/10/yelp-menus-connecting-people-with-great-local-food-porn.html
[2]: http://ocrsdk.com/
[3]: https://github.com/abbyysdk/ocrsdk.com/tree/master/Python
[4]: https://code.google.com/p/tesseract-ocr/